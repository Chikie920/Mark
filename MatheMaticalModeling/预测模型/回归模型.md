## 多元回归模型的线性与非线性

这里的线性与非线性并不是指线性函数与非线性函数，即自变量是否是线性的，而是指回归系数的线性与非线性

<img src="https://raw.githubusercontent.com/Chikie920/Mark/266f340e02a18857d4b3a9093f7577d9027fd0d3/Sources/images_math/image-20220115153107311.png" alt="image-20220115153107311" style="zoom:80%;" />

对于一元回归模型还是以自变量的线性与否判断





## 回归模型大致方法

1. 绘制散点图，判断大致关系
2. 建立回归方程并求解
3. 对回归系数进行假设检验(**F检验**-得到回归系数总体对因变量是否有影响，**t检验**-得到单个回归系数对因变量是否有影响)、区间估计等



注：当判断回归方程中哪个自变量对因变量的影响更为显著时需要将回归系数标准化后再比较



## 线性回归模型



**模型方程：**
$$
y = b_0 + b_1*x + \epsilon， \epsilon \in N(0, \delta^2)
$$
 `b_0`为截距， `b_1`为斜率， `b_0 b_1`称为回归系数，`epsilon`为随机误差项



### 回归方程求解



根据样本运用**最小二乘法**可求得回归系数估计值，得到如下回归方程
$$
\widehat{y_i} = \widehat{b_0} + \widehat{b_1}*x_i
$$



![image-20220316163832795](C:\Users\Mirai\AppData\Roaming\Typora\typora-user-images\image-20220316163832795.png)

`regress()`可返回参数估计与估计区间、残差、残差区间、拟合优度、F值与对于P值、方差



### 假设检验部分



模型**误差平方和**`SSE` 、模型**回归平方和**`SSR`、模型**总离差(偏差)平方和**`SST`
$$
SSE = \sum_{i=1}^n(y_i-\widehat{y_i})^2
$$

$$
SSR = \sum_{i=1}^n(\widehat{y_i}-\overline{y_i})^2
$$

$$
SST = \sum_{i=1}^n(y_i-\overline{y_i})^2
$$

$$
\overline{y_i}为回归方程所求值；y_i为样本值；\overline{y_i}为样本平均值
$$

$$
SST = SSE+SSR
$$





#### 回归方程总体显著性检验-F检验



**F检验-得到回归系数总体对因变量是否有影响**，**当只有一个自变量时与t检验没有区别**

检验自变量总体对因变量之间的线性关系，用于证明模型有效



##### 假设

令原假设H0：b1 = b2 = b3 = ... = bk = 0

备择假设H1: 为回归系数至少有一个不为0



**F统计量**
$$
F = \frac{SSR/k}{SSE/(n-k-1)}, F ~ (k, n-k-1)   (k为自变量个数)
$$
F是服从`(k, n-k-1)`的F分布的

通过公式可以求得F值，再通过查表得到在置信水平a下对应自由度的F_a值，若F < F_a则接受H0，否则拒绝H0



###### 使用matlab检验

可使用matlab函数`vartest2()`

```matlab
[h, p] = vartest2(x, y);
```

`h` - **假设检验结果**，1则拒绝原假设

`p`- **p值**



还可以通过**拟合优度(判断系数)**`R^2`的大小得到回归方程的因变量与自变量的关系程度，约接近1越好(通常大于0.8)

实际建模时加上去更完整
$$
R^2 =\frac{SSR}{SST} = 1 - \frac{SSE}{SST}
$$


#### 回归系数显著性检验-t检验

**t检验**-**得到单个回归系数对因变量是否有影响**，**用于检验每个(偏)回归系数的显著性-是否与0有显著差异**



##### 假设

令原假设H0：b1 = 0

备择假设H1:  b1不为0



##### 检验

可使用matlab函数`ttest2()`

```matlab
[h, p] = ttest2(x, y);
```

`h` - **假设检验结果**，1则拒绝原假设

`p`- **p值**



若检验不通过，可将未通过的自变量剔除再次进行回归，当有多个不通过时，先剔除一个再次回归后并检验，常数项未通过不要轻易剔除

这种多次回归的方法称为**逐步回归**



#### 关于matlab的regstats()函数

该函数用于回归诊断，比手动求回归系数与假设检验更便捷(甚至不是一点半点...)

```matlab
stats = regstats(y, x);
```

细节见代码



## 一元非线性回归模型

**方法：将非线性函数转化为线性函数**

<img src="https://raw.githubusercontent.com/Chikie920/Mark/266f340e02a18857d4b3a9093f7577d9027fd0d3/Sources/images_math/image-20220115195919642.png" alt="image-20220115195919642" style="zoom:80%;" />



<img src="https://raw.githubusercontent.com/Chikie920/Mark/266f340e02a18857d4b3a9093f7577d9027fd0d3/Sources/images_math/image-20220115195939437.png" alt="image-20220115195939437" style="zoom:80%;" />



**记得将变换后的回归模型还原**



## 多元线性回归模型



**模型方程：**
$$
y = b_0 + b_1*x_1 + b_2*x_2 + ... + b_k*x_k + \epsilon， \epsilon \in N(0, \delta^2)
$$
 `b_0`为回归常数， `b_i`为偏回归系数



**求解方法同理，使用最小二乘法求回归系数，当然也可以直接regstats()函数梭哈**



### 标准化回归系数

**在比较自变量的影响程度时需要标准化回归系数**

**公式：标准化回归系数 = 未标准化回归系数 * 该自变量的标准差 / 因变量的标准差**



### 关于经济研究问题

对于经济研究等问题时需要对回归方程取ln



关于异方差与多重共线性等后续添加...



## 多元非线性回归模型

**方法：将非线性系数转化为线性系数，即取ln**





## 多重共线性



## 论文写作



